{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHjVqzTLN8wMi5QWBq574P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/NLP-Assignment/blob/main/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Can you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN? And a vector-to-sequence RNN?\n",
        "\n",
        "In Sequence to Sequence Learning, RNN is trained to map an input sequence to an output sequence which is not necessarily of the same length. Applications are speech recognition, machine translation, image captioning and question answering.\n",
        "\n",
        "A variable-length context vector can be used instead of a ﬁxed-size vector. An Attention mechanism can be used to produces a sequence of vectors from the encoder RNN from each time step of the input sequence. The Decoder learns to pay selective attention to the vectors to produce the output at each time step.\n"
      ],
      "metadata": {
        "id": "dPYG_19zzj75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Why do people use encoder–decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation?\n",
        "\n",
        "This two-step model, called an Encoder–Decoder, works much better than trying to translate on the fly with a single sequence-to-sequence RNN (like the one represented on the top left), since the last words of a sentence can affect the first words of the translation, so you need to wait until you have heard the whole "
      ],
      "metadata": {
        "id": "9pY0fADv0B_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.How could you combine a convolutional neural network with an RNN to classify videos?\n",
        "\n",
        "Researchers have used layered CNN-RNN pairs where the output of the CNN is input to the RNN. Logically the RNN has also been replaced with LSTMs to create a more 'in the moment' description of each video segment.\n",
        "\n",
        "Each video is converted into sequential images and passed onto the CNN to extract spatial features. The outputs are then passed into a recurrent sequence learning model (i.e. LSTM) to identify temporal features within the image sequence."
      ],
      "metadata": {
        "id": "5iFCSy6V0Q5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.What are the advantages of building an RNN using dynamic_rnn() rather than static_rnn()?\n",
        "\n"
      ],
      "metadata": {
        "id": "4Ur6Bagc0ayf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.How can you deal with variable-length input sequences? What about variable-length output sequences?\n",
        "\n",
        "In the case of variable length sequence prediction problems, this requires that your data be transformed such that each sequence has the same length. This vectorization allows code to efficiently perform the matrix operations in batch for your chosen deep learning algorithms"
      ],
      "metadata": {
        "id": "fjQ9jtYd0s2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is a common way to distribute training and execution of a deep RNN across multiple GPUs?\n",
        "\n",
        "here are generally two ways to distribute computation across multiple devices: Data parallelism, where a single model gets replicated on multiple devices or multiple machines. Each of them processes different batches of data, then they merge their results"
      ],
      "metadata": {
        "id": "BX5WkuYi08wH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HCyqoyNA0N-f"
      }
    }
  ]
}